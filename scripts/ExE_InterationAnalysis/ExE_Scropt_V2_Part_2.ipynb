{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExE Interaction Analysis\n",
    "------------------------\n",
    "\n",
    "\n",
    "<h4>Part 1: Queries</h4>\n",
    "\n",
    "CREATE A SINGLE SEARCH PROCESS\n",
    "<ol>\n",
    "<li>Entry of a List of IDs and Descriptions</li>\n",
    "<li>Rotate word_to_term for the Descriptions</li>\n",
    "<li>Search the TermMap</li>\n",
    "<li>Super table (ID, Description, Word, Term, Term_1, Term_2, ID_1, ID_2,\n",
    "    Groups/Categories, counts)</li>\n",
    "</ol>\n",
    "With this super table, the user can perform the cleaning as needed, thus\n",
    "eliminating categories that are not of interest\n",
    "\n",
    "<h4>Part 2: ExE LRT ANALYSY</h4>\n",
    "<ol>\n",
    "<li>Define Main Table, Outcomes and Covariantes</li>\n",
    "<li>Run the ExE Interation by Outcome and Map Pairs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    v_root = Path(__file__).parents[2]\n",
    "    sys.path.append(os.path.abspath(v_root))\n",
    "except Exception as e:\n",
    "    print(\"erro: \", e)\n",
    "    raise\n",
    "\n",
    "from igem import epc\n",
    "\n",
    "# Data Path\n",
    "v_path = v_root / \"_utils\" / \"jiayan_analysis\" / \"files\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 5: Define Main Table, Outcomes and Covariantes\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# DataFrame to collect results\n",
    "df_results_discover_final = pd.DataFrame()\n",
    "df_results_replicate_final = pd.DataFrame()\n",
    "list_results_discover = []\n",
    "list_results_replicate = []\n",
    "\n",
    "# Read NHANES Main Table\n",
    "df_maintable = epc.load.from_csv(str(v_path / \"MainTable.csv\"))\n",
    "\n",
    "# list of Outcomes\n",
    "list_outcome = [\n",
    "    \"LBXHGB\",\n",
    "]\n",
    "\n",
    "# list of Covariants\n",
    "list_covariant = [\n",
    "    \"female\",\n",
    "    \"black\",\n",
    "    \"mexican\",\n",
    "    \"other_hispanic\",\n",
    "    \"other_eth\",\n",
    "    \"SDDSRVYR\",\n",
    "    \"BMXBMI\",\n",
    "    \"SES_LEVEL\",\n",
    "    \"RIDAGEYR\",\n",
    "    \"LBXCOT\",\n",
    "    \"IRON_mg\",\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 6: Run the ExE Interation by Outcome and Map Pairs\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# --> Start: DELETE THIS CODE ON FLY\n",
    "# READ\n",
    "df_nhanes_map = epc.load.from_csv(str(v_path / \"gepairs.csv\"), index_col=None)\n",
    "df_nhanes_map = df_nhanes_map.rename(\n",
    "    columns={\"NHANESID_var1\": \"var_x\", \"NHANESID_var2\": \"var_y\"}\n",
    ")\n",
    "list_remove = [\n",
    "    \"pneu\",\n",
    "    \"current_asthma\",\n",
    "    \"EVER\",\n",
    "    \"any\",\n",
    "    \"ATORVASTATIN\",\n",
    "    \"AZITHROMYCIN\",\n",
    "    \"CARVEDILOL\",\n",
    "    \"hepb\",\n",
    "    \"FENOFIBRATE\",\n",
    "    \"FLUOXETINE\",\n",
    "    \"BUPROPION\",\n",
    "    \"GLYBURIDE\",\n",
    "    \"ASPIRIN\",\n",
    "    \"heroin\",\n",
    "    \"ALENDRONATE\",\n",
    "    \"METFORMIN\",\n",
    "    \"ESTRADIOL\",\n",
    "    \"OMEPRAZOLE\",\n",
    "    \"NIFEDIPINE\",\n",
    "    \"PREDNISONE\",\n",
    "    \"PIOGLITAZONE\",\n",
    "    \"ROFECOXIB\",\n",
    "    \"ALBUTEROL\",\n",
    "    \"SPIRONOLACTONE\",\n",
    "    \"SIMVASTATIN\",\n",
    "    \"SERTRALINE\",\n",
    "    \"LOVASTATIN\",\n",
    "    \"LOSARTAN\",\n",
    "    \"cocaine\",\n",
    "    \"DIGOXIN\",\n",
    "    \"CELECOXIB\",\n",
    "]\n",
    "for i in list_remove:\n",
    "    df_nhanes_map = df_nhanes_map[~df_nhanes_map[\"var_x\"].str.contains(i)]\n",
    "    df_nhanes_map = df_nhanes_map[~df_nhanes_map[\"var_y\"].str.contains(i)]\n",
    "# fix the df index\n",
    "df_nhanes_map = df_nhanes_map.reset_index()\n",
    "df_nhanes_map = epc.modify.colfilter(df_nhanes_map, skip=\"ID\")\n",
    "# --> End: DELETE\n",
    "\n",
    "# Run each Outcome in defined list\n",
    "for i_outcome in list_outcome:\n",
    "    # Run each pair map in df_nhanes_map\n",
    "    for i_mappair in df_nhanes_map.index:\n",
    "        # get Exposomes\n",
    "        e1 = df_nhanes_map[\"var_x\"][i_mappair]\n",
    "        e2 = df_nhanes_map[\"var_y\"][i_mappair]\n",
    "\n",
    "        # Keep only the necessary columns to run Interations Study\n",
    "        df_maintable_exe = df_maintable.loc[\n",
    "            :, list_covariant + list_outcome + list([e1, e2])\n",
    "        ]\n",
    "        df_maintable_exe = df_maintable_exe.fillna(0)\n",
    "\n",
    "        # Filter data table to Discovery Data\n",
    "        df_maintable_exe = df_maintable_exe[\n",
    "            df_maintable_exe[\"SDDSRVYR\"].isin([1, 2])\n",
    "            ]\n",
    "\n",
    "        # Run Interation Study\n",
    "        Interation_Study = epc.analyze.interaction_study(\n",
    "            data=df_maintable_exe,\n",
    "            outcomes=i_outcome,\n",
    "            interactions=[(e1, e2)],\n",
    "            covariates=list_covariant,\n",
    "        )\n",
    "\n",
    "        # Save results in list: outcome/e1/e2/converged/LRT_pvalue/Bonfp\n",
    "        list_results_discover.append(\n",
    "            [\n",
    "                Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "                Interation_Study.Converged.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0] * len(df_nhanes_map),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Transf result list in df with Bonfp < 0.05\n",
    "    df_results_discover = pd.DataFrame(\n",
    "        list_results_discover,\n",
    "        columns=[\n",
    "            \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"LRT_pvalue\", \"Bonfp\"\n",
    "            ],\n",
    "    )\n",
    "    df_results_discover = df_results_discover.loc[\n",
    "        df_results_discover[\"Bonfp\"] <= 0.05\n",
    "        ]\n",
    "\n",
    "    # Run Replicate for all discovery result with Bonfp < 0.05\n",
    "    for x in df_results_discover.itertuples(index=False):\n",
    "        e1 = x.Term1\n",
    "        e2 = x.Term2\n",
    "\n",
    "        # Keep only the necessary columns to run Interations Study\n",
    "        df_maintable_exe = df_maintable.loc[\n",
    "            :, list_covariant + list_outcome + list([e1, e2])\n",
    "        ]\n",
    "        df_maintable_exe = df_maintable_exe.fillna(0)\n",
    "\n",
    "        # Filter data table to Replicate Data\n",
    "        df_maintable_exe = df_maintable_exe[\n",
    "            df_maintable_exe[\"SDDSRVYR\"].isin([3, 4])\n",
    "            ]\n",
    "\n",
    "        # Run Interation Study\n",
    "        Interation_Study = epc.analyze.interaction_study(\n",
    "            data=df_maintable_exe,\n",
    "            outcomes=i_outcome,\n",
    "            interactions=[(e1, e2)],\n",
    "            covariates=list_covariant,\n",
    "        )\n",
    "\n",
    "        # Save results in list: outcome/e1/e2/converged/LRT_pvalue/Bonfp\n",
    "        list_results_replicate.append(\n",
    "            [\n",
    "                Interation_Study.LRT_pvalue.index.levels[2][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[0][0],\n",
    "                Interation_Study.LRT_pvalue.index.levels[1][0],\n",
    "                Interation_Study.Converged.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0],\n",
    "                Interation_Study.LRT_pvalue.values[0] * len(\n",
    "                    df_results_discover\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Transf result list in df with Bonfp < 0.05\n",
    "    df_results_replicate = pd.DataFrame(\n",
    "        list_results_replicate,\n",
    "        columns=[\n",
    "            \"Outcome\", \"Term1\", \"Term2\", \"Converged\", \"LRT_pvalue\", \"Bonfp\"\n",
    "            ],\n",
    "    )\n",
    "    df_results_replicate = df_results_replicate.loc[\n",
    "        df_results_replicate[\"Bonfp\"] <= 0.05\n",
    "    ]\n",
    "\n",
    "    df_results_discover_final = df_results_discover_final.append(\n",
    "        df_results_discover\n",
    "    ).reset_index(drop=True)\n",
    "    df_results_replicate_final = df_results_replicate_final.append(\n",
    "        df_results_replicate\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "print(df_results_discover_final)\n",
    "print(df_results_replicate_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
