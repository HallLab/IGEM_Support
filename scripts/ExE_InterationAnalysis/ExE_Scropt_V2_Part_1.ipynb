{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExE Interaction Analysis\n",
    "------------------------\n",
    "\n",
    "\n",
    "<h4>Part 1: Queries</h4>\n",
    "\n",
    "CREATE A SINGLE SEARCH PROCESS\n",
    "<ol>\n",
    "<li>Entry of a List of IDs and Descriptions</li>\n",
    "<li>Rotate word_to_term for the Descriptions</li>\n",
    "<li>Search the TermMap</li>\n",
    "<li>Super table (ID, Description, Word, Term, Term_1, Term_2, ID_1, ID_2,\n",
    "    Groups/Categories, counts)</li>\n",
    "</ol>\n",
    "With this super table, the user can perform the cleaning as needed, thus\n",
    "eliminating categories that are not of interest\n",
    "\n",
    "<h4>Part 2: ExE LRT ANALYSY</h4>\n",
    "<ol>\n",
    "<li>Define Main Table, Outcomes and Covariantes</li>\n",
    "<li>Run the ExE Interation by Outcome and Map Pairs</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Local Environment to consider igem local folder as a Package\n",
    "current_path = Path.cwd()\n",
    "try:\n",
    "    v_root = Path.cwd().parents[1]\n",
    "    sys.path.append(os.path.abspath(v_root))\n",
    "except Exception as e:\n",
    "    print(\"erro: \", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpy2 ModuleSpec(name='rpy2', loader=<_frozen_importlib_external.SourceFileLoader object at 0x13a52ab30>, origin='/Users/andrerico/DEV/projects/igem_sandbox/venv/lib/python3.10/site-packages/rpy2/__init__.py', submodule_search_locations=['/Users/andrerico/DEV/projects/igem_sandbox/venv/lib/python3.10/site-packages/rpy2'])\n"
     ]
    }
   ],
   "source": [
    "# Import IGEM folder as a Package\n",
    "# Return rpy2 msm.\n",
    "from igem import epc, ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Path\n",
    "v_path = v_root / \"scripts\" / \"ExE_InterationAnalysis\" / \"files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3,174 observations of 36 variables\n",
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 10 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 36 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 26 continuous variables\n",
      "\t2 of 10 unknown variables\n",
      "================================================================================\n",
      "Loaded 3,304 observations of 6 variables\n",
      "================================================================================\n",
      "Running colfilter\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mWARNING: 5 variables need to be categorized into a type manually\u001b[0m\n",
      "Keeping 2 of 6 variables:\n",
      "\t0 of 0 binary variables\n",
      "\t0 of 0 categorical variables\n",
      "\t0 of 1 continuous variables\n",
      "\t2 of 5 unknown variables\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# STEP 1: Get IGEM Terms from a ID and Description NHAMES List\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_nhames_desc = epc.load.from_csv(str(v_path / \"nhanes_description.csv\"))\n",
    "df_nhames_desc = epc.modify.colfilter(df_nhames_desc, only=[\"var\", \"var_desc\"])\n",
    "df_nhames_desc[\"var_desc\"].to_csv(\n",
    "    str(v_path / \"nhanes_description_igem.csv\"), index=False\n",
    ")\n",
    "\n",
    "# From NHAMES get IGEM Terms\n",
    "# df_ge_terms = ge.filter.word_to_term(str(v_path /\n",
    "#   \"nhanes_description_strings.csv\"))\n",
    "df_terms = epc.load.from_csv(\n",
    "    str(v_path / \"nhanes_description_terms.csv\"), index_col=False\n",
    ")\n",
    "df_terms = epc.modify.colfilter(\n",
    "    df_terms, only=[\"fatores\", \"term\"]\n",
    ")  # TODO: change output format\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 2: Get TermMap from Terms founds in step 1\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Delete Terms that is not target study\n",
    "for x in [\"anat\", \"go\", \"path\", \"meta:hmdb0002111\"]:\n",
    "    df_terms = df_terms[~df_terms[\"term\"].astype(str).str.startswith(x)]\n",
    "df_terms = df_terms.dropna()\n",
    "df_terms = df_terms.drop_duplicates(subset=\"fatores\", keep=\"last\")\n",
    "\n",
    "# Return NHANES ID to df_terms\n",
    "df_terms[\"fatores\"] = df_terms[\"fatores\"].str.lower()\n",
    "df_nhames_desc[\"var_desc\"] = df_nhames_desc[\"var_desc\"].str.lower()\n",
    "df_terms = df_terms.merge(\n",
    "    df_nhames_desc, left_on=\"fatores\", right_on=\"var_desc\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Convert DF column term to Terms List\n",
    "list_term = df_terms[\"term\"].tolist()\n",
    "\n",
    "# Get all Term Map from Terms List\n",
    "df_term_map = ge.filter.term_map(term=list_term)\n",
    "\n",
    "# Clear fields from Term Map DF\n",
    "df_term_map = epc.modify.colfilter(df_term_map, only=[\"term_1\", \"term_2\"])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 3: Replace Terms ID by NHANES ID\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Replace Terms by NHANES ID on df_term_map\n",
    "# TODO: I could use epc.modify.merge_variables because we don`t have to key\n",
    "df_nhanes_map = df_term_map.merge(\n",
    "    df_terms, left_on=\"term_1\", right_on=\"term\", how=\"left\"\n",
    ")\n",
    "df_nhanes_map = df_nhanes_map.merge(\n",
    "    df_terms, left_on=\"term_2\", right_on=\"term\", how=\"left\"\n",
    ")\n",
    "\n",
    "df_nhanes_map = epc.modify.colfilter(\n",
    "    df_nhanes_map, only=[\"var_x\", \"var_desc_x\", \"var_y\", \"var_desc_y\"]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 4: Clean df_nhanes_map to match the study target\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Delete maps without one of the nhanes ID\n",
    "df_nhanes_map = df_nhanes_map.dropna()\n",
    "\n",
    "# Define list of nhanes ID that will not match the study target\n",
    "list_remove = [\n",
    "    \"pneu\",\n",
    "    \"current_asthma\",\n",
    "    \"EVER\",\n",
    "    \"any\",\n",
    "    \"ATORVASTATIN\",\n",
    "    \"AZITHROMYCIN\",\n",
    "    \"CARVEDILOL\",\n",
    "    \"hepb\",\n",
    "    \"FENOFIBRATE\",\n",
    "    \"FLUOXETINE\",\n",
    "    \"BUPROPION\",\n",
    "    \"GLYBURIDE\",\n",
    "    \"ASPIRIN\",\n",
    "    \"heroin\",\n",
    "    \"ALENDRONATE\",\n",
    "    \"METFORMIN\",\n",
    "    \"ESTRADIOL\",\n",
    "    \"OMEPRAZOLE\",\n",
    "    \"NIFEDIPINE\",\n",
    "    \"PREDNISONE\",\n",
    "    \"PIOGLITAZONE\",\n",
    "    \"ROFECOXIB\",\n",
    "    \"ALBUTEROL\",\n",
    "    \"SPIRONOLACTONE\",\n",
    "    \"SIMVASTATIN\",\n",
    "    \"SERTRALINE\",\n",
    "    \"LOVASTATIN\",\n",
    "    \"LOSARTAN\",\n",
    "    \"cocaine\",\n",
    "    \"DIGOXIN\",\n",
    "    \"CELECOXIB\",\n",
    "]\n",
    "for i in list_remove:\n",
    "    df_nhanes_map = df_nhanes_map[~df_nhanes_map[\"var_x\"].str.contains(i)]\n",
    "    df_nhanes_map = df_nhanes_map[~df_nhanes_map[\"var_y\"].str.contains(i)]\n",
    "\n",
    "# fix the df index\n",
    "df_nhanes_map = df_nhanes_map.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
